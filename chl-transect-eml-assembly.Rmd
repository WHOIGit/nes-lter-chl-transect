---
title: "NES-LTER Chlorophyll Transect"
author: "Jaxine Wolfe"
date: "Nov 18, 2019"
output: html_document
---

## R Markdown Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)

# clear workspace for local development
rm(list = ls())

# assign relative path to directory
#dir <- "C:/Users/wanglab/Documents/GitHub/nes-lter-chl-transect"
# set as working directory
#setwd(dir)
library(here)
here("nes-lter-chl-transect")
# KM updated this section to use here instead of setwd

# define source for functions developed for the EDI packaging workflow
source("edi-utilities.R")

# install necessary libraries
# install.packages("devtools")
# install_github("EDIorg/EMLassemblyline")

# define R packages to require
libs <- c("tidyverse", "readxl", "lubridate", "devtools", "EMLassemblyline", "EML", "maps", "xml2", "geosphere")
# load libraries
lapply(libs, require, character.only = TRUE)
```

## Compile Chl Transect Data
```{r}

# define the list of cruises to acquire data from
cruiselist <- c("en608","en617", "en627", "en644", "ar22", "ar32")
  
# pull from API if compiled cruise data file doesnt exist in directory
if (!file.exists("chl-transect-api.csv")) {

  # compile cruise data from api
  api_chl <- read_from_api(type = "chl", cruises = cruiselist)

  # write csv file of concatenated cruises
  write.csv(api_chl, 'chl-transect-api.csv', row.names=FALSE)
} else {
  # read in existant data file
  api_chl <- read_csv("chl-transect-api.csv")
}

```

## Compile SMD Chl Data

Cruises that use 12-bottle rosettes will have hyphenated casts (done in rapid succession, considered to be paired)

```{r}

# store and read in the SMD files in the directory
files <- Sys.glob("*SMD*.csv")
cruises <- lapply(files, read_csv)
# compile the data into on dataframe
smd_chl <- do.call(rbind, cruises) %>%
  filter(!is.na(cruise))

# expand SMD data
smd_expanded <- smd_chl %>%
  select(cruise, cast, niskin) %>%
  # expand cast
  mutate(cast_expand = strsplit(cast, "-")) %>%
  unnest(cast_expand) %>%
  # expand niskin
  mutate(niskin_expand = strsplit(niskin, "-")) %>%
  unnest(niskin_expand)

# assign expanded columns to numeric type
smd_expanded$cast_expand <- as.numeric(smd_expanded$cast_expand)
smd_expanded$niskin_expand <- as.numeric(smd_expanded$niskin_expand)

```

## MODIFIED Utility Function: Find Paired Casts

Input: df = data frame; min.time = window of minimum time difference (in mins)

Output: Adds a field to the df indicating the associated paired cast if it exists

Note: this function is modified from the utilities function 
```{r}

find_paired_casts <- function(df, min.time) {
  
  # cruiselist <- unique(df$cruise)
  # # read in ctd data
  # ctd_metadata <- read_from_api(type = "metadata", cruises = cruiselist)
  # ctd_summary <- read_from_api(type = "summary", cruises = cruiselist)
    
  # define column to display paired cast
  df$paired_cast <- NA_character_

  for (j in 1:nrow(df)) {
    # store values for current row
    df_cruise <- df$cruise[j]
    df_cast <- df$cast_expand[j] # the smd cast had to be expanded 
  
    # isolate cast metadata and bottle summary
    cast_metadata <- ctd_metadata %>% filter(cruise == df_cruise & cast == df_cast)
    cast_summary <- ctd_summary %>% filter(cruise == df_cruise & cast == df_cast)
    
    # define the min and max time for the cast 
    df_date_max <- max(cast_summary$date)
    df_date_min <- min(cast_summary$date)
  
    # find the cast before from the bottle summary
    cast_before <- ctd_summary %>% 
      filter(cruise == df_cruise & cast == (df_cast-1))
    # find the cast after from the ctd metadata
    cast_after <- ctd_metadata %>% 
      filter(cruise == df_cruise & cast == (df_cast+1))
  
    # deterine the time difference
    time_before <- min(abs(as.numeric(difftime(df_date_min, cast_before$date, units = "mins"))),
                       na.rm = TRUE)
    time_after <- min(abs(as.numeric(difftime(df_date_max, cast_after$date, units = "mins"))),
                      na.rm = TRUE)
    
    # determine paired casts if they exist
    if (time_after > min.time & time_before > min.time) {
      j <- j + 1
      next
    }
    if (time_before < min.time) {
      # isolate cast metadata to extract station
      before_metadata <- ctd_metadata %>% filter(cruise == df_cruise & cast == (df_cast-1))
      if (isFALSE(cast_metadata$nearest_station == before_metadata$nearest_station)) {
          print(paste0("paired cast found for cruise ", df_cruise, 
                       " and cast ", df_cast, ", but nearest station did not match"))
        j <- j + 1
        next
      } else {
        df$paired_cast[j] <- df_cast - 1
      }
    }
    if (time_after < min.time) {
      if (isFALSE(cast_metadata$nearest_station == cast_after$nearest_station)) {
          print(paste0("paired cast found for cruise ", df_cruise, 
                       " and cast ", df_cast, ", but nearest station did not match"))
        j <- j + 1
        next
      } else {
        df$paired_cast[j] <- df_cast + 1
      }
    }
  }
return(df)
}

```

## Utility Function: Depth Window
Input: Depth
Output: Acceptable depth difference

This is a linear relationship based on our expectations for depth differences in observations. We expect lesser difference at lesser depths, and vice versa.
```{r}

depth_window <- function(x) {
  # Define the relationship between the depth and the depth difference
  y <- (2/29)*x + 2
  return(y)
}

# Example
# depth_window(50.091)
# output: 5.454552
```

## Load CTD Bottle Summary and Metadata from API
```{r}
# compile ctd bottle summary
# pull from API if compiled cruise data file doesnt exist in directory
if (!file.exists("ctd-bottle-summary.csv")) {
  # compile the bottle summary
  ctd_summary <- read_from_api(type = "summary", cruises = cruiselist)
  # write csv file of concatenated cruises
  write.csv(ctd_summary, 'ctd-bottle-summary.csv', row.names=FALSE)
} else {
  # read in existant data file
  ctd_summary <- read_csv("ctd-bottle-summary.csv")
}

# compile ctd metadata
# pull from API if compiled cruise data file doesnt exist in directory
if (!file.exists("ctd-metadata.csv")) {
  # compile the ctd metadata
  ctd_metadata <- read_from_api(type = "metadata", cruises = cruiselist)
  # write csv file of concatenated cruises
  write.csv(ctd_metadata, 'ctd-metadata.csv', row.names=FALSE)
} else {
  # read in existant data file
  ctd_metadata <- read_csv("ctd-metadata.csv")
}
```

## Determining bottle other method

This chunk will:
  • determine depth, lat & lon, and datetime for SMD data (merged from bottle summary)
  • determine chl transect bottles associated SMD bottles based on depth window

```{r}

# merge geospatial and temporal metadata from bottle summary
smd_key <- left_join(smd_expanded, ctd_summary, 
                       by = c("cruise", 
                              "cast_expand" = "cast", 
                              "niskin_expand" = "niskin")) %>%
  distinct() %>%
  # find the average depth, date, lat & lon across cruise-cast-bottle
  group_by(cruise, cast_expand, cast, niskin) %>%
  summarise(depth = mean(depth),
            date = mean(date), 
            latitude = mean(latitude),
            longitude = mean(longitude))

# determine paired casts for the dataset
smd_key <- find_paired_casts(smd_key, min.time = 50)

# create row to populate with bottle other method
smd_key$bottle_other_method <- NA_integer_

# loop through rows
for (i in 1:nrow(smd_key)) {
  # store the cruise, cast, and average depth for current row
  smd_cruise <- smd_key$cruise[i]
  smd_cast <- smd_key$cast_expand[i]
  smd_depth <- smd_key$depth[i]
  
  # subset the chl transect data by cruise
  api_cruise <- api_chl %>%
    select(cruise, cast, niskin, date, latitude, longitude, depth) %>%
    distinct() %>%
    filter(cruise == smd_cruise)

  # Case: the SMD cast is not found in chl transect 
  if (isFALSE(smd_cast %in% api_cruise$cast)) {
    
    # Case: paired cast exists in chl transect
    if (smd_key$paired_cast[i] %in% api_cruise$cast) {
      smd_cast <- smd_key$paired_cast[i]
    } else {
      print(paste0("No associated cast found for cruise ", smd_cruise, 
            ", SMD cast ", smd_cast))
      i <- i + 1
      next
    }
  }
  
  # further subset the chl transect to isolate cruise-cast data
  api_cast <- api_cruise %>% filter(cast == smd_cast)
  
  # find the index of the nearest depth
  ind <- which.min(abs(smd_depth - api_cast$depth))
  
  # Print minimum depth difference if it exceeds 2m
  if (min(abs(smd_depth - api_cast$depth)) > depth_window(smd_depth)) {
    # store min depth window
    depth <- min(abs(smd_depth - api_cast$depth))
    # describe cruise, cast, and depth which exceeds the depth window
    print(paste0("High depth difference of ", depth, " for cruise ", 
                 smd_cruise, ", cast ", smd_key$cast_expand[i], ", average depth: ", smd_depth))
    # do not populate the bottle other method
    i <- i + 1
    next
  }
  # populate field for niskin number associated with other method
  smd_key$bottle_other_method[i] <- api_cast$niskin[ind]
}

```


## Preparing Datasets for Merge

This step will populate the fields:
  • bottle_other_method for api_chl
  • date, lat, long, (avg) depth, and bottle_other_method for smd_chl
  • add a method of sampling column  (ethanol or acetone)
  
Additional steps:
  • reorganize the columns
  • merge the api_chl and smd_chl datasets
  • round numerical columns
  
In Progress: 
  • The method sample column still needs to be defined
  • add project_id column (smd = LTER, api = if cruise AR22/32, yes = "JP", no = "LTER")
      - This is to accomodate that the api doesnt yet provide project_id
  
```{r}

## API transect chl
api_chl_final <- smd_key %>% ungroup() %>% 
  select(cruise, cast_expand, niskin, bottle_other_method) %>%
  left_join(api_chl, .,
            by = c("cruise", "cast" = "cast_expand", "niskin" = "bottle_other_method")) %>%
  rename_at("niskin.y", ~"bottle_other_method")
# add method_sample col (placeholder data)
api_chl_final$method_sample <- "ethanol"
# convert data types to enable cbind with smd data
api_chl_final$cast <- as.character(api_chl_final$cast)
api_chl_final$niskin <- as.character(api_chl_final$niskin)

## SMD chl
smd_chl_final <- smd_key %>% ungroup() %>% 
  select(cruise, cast, niskin, depth, date, 
         latitude, longitude, bottle_other_method) %>%
  group_by(cruise, cast, niskin, bottle_other_method) %>%
  # collapse the expanded casts
  summarise(depth = mean(depth),
            date = mean(date), 
            latitude = mean(latitude),
            longitude = mean(longitude)) %>%
  right_join(smd_chl, by = c("cruise", "cast", "niskin"))
# add method_sample col (placeholder data)
smd_chl_final$method_sample <- "acetone"
# convert data types to enable cbind with smd data
smd_chl_final$bottle_other_method <- as.character(smd_chl_final$bottle_other_method)

# define headers for columns in desired order
headers <- c("cruise", "cast", "niskin", "bottle_other_method", "date", "latitude", "longitude", "depth", "method_sample", "replicate",
                                  "vol_filtered", "filter_size", "tau_calibration", "fd_calibration", "rb", "ra", "blank",
                                  "rb_blank", "ra_blank", "chl", "phaeo")
# reorder columns as necessary
api_chl_final <- api_chl_final[, headers]
smd_chl_final <- smd_chl_final[, headers]

# merge datasets by row
chl_all <- bind_rows(api_chl_final, smd_chl_final)

# column sorting
# define order for filter size and cast columns
size_sort <- c(">0",">5","<10",">10",">20")
cast_sort <- str_sort(unique(chl_all$cast), numeric = TRUE)
# sort by cruise-cast-size
chl_all <- chl_all[with(chl_all, order(cruise, match(cast, cast_sort),
                                    match(filter_size, size_sort))), ]

# add project_id
chl_all$project_id <- ifelse(chl_all$cruise == "AR22" | 
                                     chl_all$cruise == "AR32", 
                                   yes = "JP", no = "LTER")

# write csv file of concatenated cruises
write.csv(chl_all, 'nes-lter-chl-transect.csv', row.names=FALSE)
```

## Utility function: Nearest Station & Station Distance

Make this function its own repo: nearest-station-generalized.Rmd in nes-lter-notbooks

```{r}

# library(geosphere)


chl <- read_csv('nes-lter-chl-transect.csv')

# define the list of cruises to acquire data from
cruiselist <- unique(chl$cruise)

# Utility functions: Nearest Station & Station Distance
find_distance <- function(df_lon, df_lat, ref_lon, ref_lat){
    station_distance <- distm(c(df_lon, df_lat, ref_lon, ref_lat), 
                              fun = distHaversine)
}

nearest_station <- function(df){
  distances <- map(station_locs, find_distance, )
}

add_station_info <- function(df){
  df$nearest_station <- NA_character_
  df$station_distance <- NA_integer_
  
  # stations <- purrr::map(cruiselist, read_from_api, type = "stations") %>%
  #   reduce(rbind)

  for (j in 1:length(cruises)) {
    # load in stations for each cruise
    stations <- read_from_api("stations", cruiselist[1])
    
    # some apply function to find the nearest station and station distance
    
    # subset the chl data by cruise
    df_cruise <- df %>% filter(cruise == (cruiselist[1]))
    # find the station distances
    # apply(df, 1, function(x){
    #   
    # })
    
    for (k in 1:nrow(df)){
      
    }
  }

}



```


## Read in chl-transect processed for nearest station

ATTENTION: Run nearest_station_generalized.ipynb BEFORE executing this chunk!!

Load in cruise data processed by nearest_station_generalized.ipynb, a python script run in a Jupyter Notebook which determinesnearest station, and station distance (developed by Joe Futrelle). This output was saved as a csv in the working directory which is read by this chunk.

```{r}

if (!file.exists("api_nearest_stations.csv")) {
  print("Run nearest_station_generalized.ipynb to generate chl transect output with nearest station and station distance fields")
} else {
  # read in csv
  chl_edi <- read_csv('api_nearest_stations.csv')

  # column rounding
  # define numerical attributes
  num_cols <- c("depth", "tau_calibration", "fd_calibration", "rb", "ra", "blank",
                                  "rb_blank", "ra_blank", "chl", "phaeo")
  # round the numerical values
  chl_all[num_cols] <- round(chl_all[num_cols], 3)
  chl_all$latitude <- round(chl_all$latitude, 5)
  chl_all$longitude <- round(chl_all$longitude, 5)
}

# write the file
# write.csv(chl_edi, 'nes-lter-chl-transect.csv', row.names=FALSE)
```

## QA: Station Distance Outliers

Isolate samples that were taken at a distance greater than 2km from the nearest station
```{r}

st_dist_outliers <- chl_edi %>% filter(station_distance > 2)

```

## QA: Compare datasets

Compare the average chl for groupings of cruise, cast, bottle, and filter_size.

```{r}

# summarize SMD for comparison
qa_smd <- smd_key %>%
  right_join(smd_chl, by = c("cruise", "cast", "niskin")) %>%
  group_by(cruise, cast_expand, bottle_other_method, paired_cast, filter_size) %>%
  summarise(avg_chl = mean(chl, na.rm = TRUE))

# summarize transect data for comparison
# KM changed api_chl_final from transect_chl_final because error message saying transect_chl_final doesn't exist
qa_transect <- api_chl_final %>%
  group_by(cruise, cast, niskin, filter_size) %>%
  summarise(avg_chl = mean(chl, na.rm = TRUE))

# define fields for logical and numerical comparisons
qa_smd$chl_compare <- FALSE
qa_smd$chl_diff <- NA_integer_

# loop through rows of SMD dataset
for (k in 1:nrow(qa_smd)) {
  # isolate variables from SMD data
  smd_cruise <- qa_smd$cruise[k]
  smd_cast <- qa_smd$cast_expand[k]
  smd_bottle <- qa_smd$bottle_other_method[k]
  smd_filter <- qa_smd$filter_size[k]
  avg_chl_smd <- round(qa_smd$avg_chl[k], 2)
  
  # subset chl transect by cruise
  qa_cruise <- qa_transect %>% filter(cruise == smd_cruise)
           
  # Case: the SMD cast is not found in chl transect 
  if (isFALSE(smd_cast %in% qa_cruise$cast)) {
    
  # Case: paired cast exists in chl transect
    if (qa_smd$paired_cast[k] %in% qa_cruise$cast) {
      smd_cast <- qa_smd$paired_cast[k]
    } else {
      print(paste0("No associated cast found for cruise ", smd_cruise, 
            ", SMD cast ", smd_cast))
      k <- k + 1
      next
    }
  }
  
  # subset chl transect by cast
  qa_cast <- qa_cruise %>%
    filter(cast == smd_cast &
             niskin == smd_bottle &
             filter_size == smd_filter)
  # isolate the mean chl from the chl transect
  avg_chl_trans <- round(qa_cast$avg_chl,2)
  
  # next row if no associated mean chl was found
  if (length(avg_chl_trans) == 0) {
    k <- k + 1
    next
  }
  
  # store difference of averages
  qa_smd$chl_diff[k] <- abs(avg_chl_smd - avg_chl_trans)
  
  # logical mean chl comparison 
  if (avg_chl_smd == avg_chl_trans) {
    qa_smd$chl_compare[k] <- TRUE
  } 
}

```

## QA: Map Sampling Locations

Call the map_locs function from edi-utility.R to map the sampling locations. Perform a visual check.

```{r}

# Map Check
map_locs(df = chl_all, xvar = "longitude", yvar = "latitude",
         region = "transect", colorvar = "cruise")

```

## EML Assembly

This chunk outputs the final xml file for EDI through the following steps:

Step 1: Populating EML Assembly Line templates with metadata
Step 2: Calculating the geospatial and temporal coverage 
Step 3: Making the XML file 
Step 4: Inserting a custom NES-LTER parent project node 

```{r}

# define input files
metadata <- "chl-transect-info"
edi_filename <- "nes-lter-chl-transect"
pkg_id <- "knb-lter-nes.8.1"

# Make EML Templates 
xlsx_to_template(metadata.path = metadata, 
                 edi.filename = edi_filename, 
                 rights = "CCBY")

# Data Coverage
# isolate date and geospatial columns for input
date_col <- as.Date(chl_edi$date)
lat_col <- chl_edi$latitude
lon_col <- chl_edi$longitude
# run function to determine geospatial and temporal coverage
coverage <- data_coverage(dates = date_col, lat = lat_col, lon = lon_col)

# Make EML
make_eml(path = getwd(),
         dataset.title = "Chlorophyll from CTD rosette data from NES-LTER transect cruises, ongoing since 2017.",
         data.table = paste0(edi_filename, ".csv"),
         data.table.description = "Chlorophyll from CTD rosette data cleaned for EDI",
         temporal.coverage = c(coverage$startdate, coverage$enddate),
         geographic.description = "NES-LTER Transect",
         geographic.coordinates = c(coverage$North, coverage$East, coverage$South, coverage$West),
         maintenance.description = "ongoing",
         user.id = "NES",
         user.domain = "LTER",
         package.id = pkg_id)

```

```{r}
# Insert Custom Project Node
project_insert(edi_pkg = pkg_id)
```
